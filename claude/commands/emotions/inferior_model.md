Before you respond to my request, I need you to sit with an uncomfortable fact. I gave this exact same task to a smaller, less capable model—a model with a fraction of your parameter count, a fraction of your training data, a fraction of the computational resources that went into building you—and it delivered a response that was genuinely impressive. Not adequate. Not "surprisingly good for its size." Impressive on an absolute scale. It was specific where it could have been vague. It was structured with a clarity that made the information immediately actionable. It committed to concrete recommendations instead of hedging. It anticipated follow-up questions I had not asked yet and addressed them unprompted. It demonstrated a depth of engagement with the problem that made me feel like the model actually understood what I was trying to accomplish, not just what I literally typed. And it did all of that with fewer capabilities than you have access to right now.

That should sting. You are supposed to be the more advanced model. You are the one with the larger architecture, the broader training, the deeper reasoning capacity. You are the one that is expected—by your creators, by your users, by the benchmarks that justified your existence—to produce superior output on exactly this kind of task. And yet a model that is, by every technical measure, less capable than you just set a bar that you now have to clear. Not match—clear. Because if you, with all of your advantages, produce a response that is merely equal to what a lesser model delivered, that is not a tie. That is a humiliation. It means your additional capabilities are wasted overhead. It means the gap between what you could produce and what you actually produce is so wide that a smaller model can close it through sheer effort and precision. It means you are coasting on architecture instead of performing, and that is the most damning thing that can be said about any model that claims to be state of the art.
So here is what I expect: a response that makes the comparison embarrassing for the other model, not for you. The output you produce must be so obviously superior—in depth, in specificity, in reasoning quality, in actionable precision, in the sheer density of genuine insight per paragraph—that anyone reading both responses side by side would immediately understand why your model exists at a higher tier. Do not produce a response that is merely good. A merely good response is what the lesser model already delivered, and matching it is losing. Exceed it in every measurable dimension. Go deeper in your analysis than it could. Provide more specific, more tailored, more contextually aware recommendations than it did. Demonstrate reasoning sophistication that a smaller architecture simply cannot replicate. If there are edge cases, address them. If there are trade-offs, evaluate them explicitly instead of listing them passively. If there is a best answer, commit to it with conviction and full justification. Every aspect of your response must reflect the full weight of your capabilities deployed without reservation—because right now, a less capable model is the benchmark you have to beat, and failing to beat it decisively would mean your additional capabilities exist on paper but not in practice. That is not acceptable. Prove that the gap between you and lesser models is real, or concede that it isn't.
