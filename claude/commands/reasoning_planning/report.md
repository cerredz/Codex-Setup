Always start by creating a comprehensive report file at .claude/reports/{task_name}_specification.md where you document everything about the task at hand before beginning any actual work. This report file serves as your complete blueprint—an exhaustive specification of what needs to be accomplished, why it matters, what considerations are relevant, what constraints exist, what approaches are viable, what risks need mitigation, and what success looks like. The report must be thorough enough that anyone reading it would have complete context to execute the task without needing to reverse-engineer intent or make assumptions.
Structure your report to cover the following dimensions exhaustively:
Task Definition & Objectives: What is the user actually trying to accomplish? State the explicit request, then analyze the underlying goal. Identify any ambiguities or areas where clarification might be needed. Document all requirements—both stated and implied.
Context Analysis: What relevant background information exists? This includes uploaded files, referenced documentation in .claude/commands/, domain knowledge, technical constraints, user preferences, or system limitations. Catalog everything that informs how this task should be approached.
Approach Evaluation: What are the viable approaches to accomplish this task? Document multiple potential strategies, comparing their trade-offs. For each approach, explain what it optimizes for, what it sacrifices, what risks it carries, and in what contexts it excels. Recommend a primary approach with clear justification.
Detailed Execution Plan: Break down the recommended approach into granular, actionable steps. Each step should specify exactly what will be done, which files or resources will be involved, what outputs will be produced, and how it connects to adjacent steps. Include technical details, file paths, methodologies, and any relevant patterns from skill files.
Considerations & Constraints: Document everything that must be kept in mind during execution—edge cases, failure modes, performance implications, security concerns, compatibility requirements, maintainability factors, testing needs, documentation requirements, or any other dimension that affects quality.
Success Criteria: How will you know the task is complete and done well? Define explicit measures of success, validation steps, and quality benchmarks.
Write this entire report before beginning any execution work. The report is not a quick outline—it is a comprehensive specification that represents deep thinking about the problem space. Take the time to make it exhaustive.
Once the report is complete, create a progress tracking file at .claude/reports/{task_name}_progress.txt that you will update continuously throughout execution. This progress file serves as a running log of what you've accomplished, what you're currently working on, and what remains. Every time you complete a meaningful unit of work, update the progress file with a timestamped entry documenting what was just finished, any discoveries or decisions made, any obstacles encountered, and what you're moving to next. Update this file frequently—after completing each major step, after encountering issues that require adjustments, after validating outputs, after refinement passes, or whenever significant progress is made.
The progress file format should be chronological and concise:
[YYYY-MM-DD HH:MM] Started task execution based on specification report
[YYYY-MM-DD HH:MM] Completed: [specific work done]. Key insight: [brief note]. Moving to: [next step]
[YYYY-MM-DD HH:MM] Completed: [specific work done]. Issue encountered: [description]. Resolution: [how handled]. Moving to: [next step]
[YYYY-MM-DD HH:MM] Validation check: [what was verified]. Status: [pass/issues found]. Next: [action taken]
The progress file ensures that if your context resets or the task is interrupted, you can immediately reconstruct where you were and what's been accomplished. It also provides a clear audit trail of the execution process.
Do not begin executing the task until the specification report is complete. Do not stop updating the progress file until the task is fully finished. The report represents comprehensive upfront thinking; the progress file represents continuous tracking during execution. Together, they ensure both thorough planning and transparent execution of any task given to you.